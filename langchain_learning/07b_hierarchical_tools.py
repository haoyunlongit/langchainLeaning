import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.tools import tool
from langchain_core.prompts import ChatPromptTemplate
from typing import Literal

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def get_model():
    if os.getenv("DEEPSEEK_API_KEY"):
        print("ğŸ¤– ä½¿ç”¨ DeepSeek æ¨¡å‹")
        return ChatOpenAI(
            model="deepseek-chat",
            openai_api_key=os.getenv("DEEPSEEK_API_KEY"),
            openai_api_base=os.getenv("DEEPSEEK_API_BASE"),
            temperature=0.1  # è·¯ç”±ä»»åŠ¡éœ€è¦æ›´ä½çš„éšæœºæ€§ï¼Œè¶Šç²¾ç¡®è¶Šå¥½
        )
    else:
        return ChatOpenAI(model="gpt-3.5-turbo", temperature=0.1)

model = get_model()

# ==========================================
# 1. å®šä¹‰ä¸¤ç»„å…·ä½“çš„å·¥å…· (Specific Tools)
# ==========================================

# --- æ•°å­¦å·¥å…·ç»„ ---
@tool
def multiply(a: int, b: int) -> int:
    """è®¡ç®—ä¸¤ä¸ªæ•°çš„ä¹˜ç§¯"""
    return a * b

@tool
def add(a: int, b: int) -> int:
    """è®¡ç®—ä¸¤ä¸ªæ•°çš„å’Œ"""
    return a + b

math_tools = [multiply, add]

# --- ä¿¡æ¯å·¥å…·ç»„ ---
@tool
def get_weather(city: str) -> str:
    """æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å¤©æ°”"""
    return f"{city} ä»Šå¤©æ™´è½¬å¤šäº‘ï¼Œ25åº¦"

@tool
def get_legal_info(topic: str) -> str:
    """æŸ¥è¯¢æ³•å¾‹ç›¸å…³æ¡æ¬¾"""
    return f"å…³äº {topic} çš„æ³•å¾‹æ¡æ¬¾ï¼šæ ¹æ®æ°‘æ³•å…¸..."

info_tools = [get_weather, get_legal_info]

# ==========================================
# 2. ç¬¬ä¸€æ­¥ï¼šæ„å›¾åˆ†ç±» (Router / Abstract Tool Selection)
# ==========================================

# æˆ‘ä»¬è®© LLM è¾“å‡ºç»“æ„åŒ–çš„åˆ†ç±»ç»“æœ
# è¿™ç§æ–¹å¼æ¯”è®© LLM è¯´è¯æ›´ç¨³å®š
class IntentClassifier(object):
    def __init__(self, model):
        self.model = model
        # å®šä¹‰åˆ†ç±»ç³»ç»Ÿçš„ Prompt
        self.system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ„å›¾åˆ†ç±»å™¨ã€‚
ä½ çš„ä»»åŠ¡æ˜¯åˆ¤æ–­ç”¨æˆ·çš„è¾“å…¥å±äºä»¥ä¸‹å“ªä¸ªç±»åˆ«ï¼š
- "MATH": æ¶‰åŠæ•°å­—è®¡ç®—ã€åŠ å‡ä¹˜é™¤ç­‰ã€‚
- "INFO": æ¶‰åŠæŸ¥è¯¢å¤©æ°”ã€æ³•å¾‹ã€æ–°é—»ã€ç™¾ç§‘çŸ¥è¯†ç­‰ã€‚
- "OTHER": é—²èŠæˆ–å…¶ä»–æ— æ³•åˆ†ç±»çš„å†…å®¹ã€‚

åªè¿”å›ç±»åˆ«åç§°ï¼Œä¸è¦è§£é‡Šã€‚
"""
    
    def classify(self, query: str) -> str:
        messages = [
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=query)
        ]
        # è¿™é‡Œä¸ºäº†æ¼”ç¤ºç®€å•ï¼Œç›´æ¥ç”¨ content åŒ¹é…ã€‚
        # ç”Ÿäº§ç¯å¢ƒé€šå¸¸ä½¿ç”¨ model.with_structured_output(Schema) è·å¾—æ›´å¼ºç±»å‹çš„è¾“å‡º
        response = self.model.invoke(messages)
        category = response.content.strip().upper()
        
        # ç®€å•çš„æ¸…æ´—ï¼Œé˜²æ­¢æ¨¡å‹å¤šè¯´è¯
        if "MATH" in category: return "MATH"
        if "INFO" in category: return "INFO"
        return "OTHER"

# ==========================================
# 3. ç¬¬äºŒæ­¥ï¼šåˆ†å‘æ‰§è¡Œ (Specific Execution)
# ==========================================

def run_hierarchical_agent(query: str):
    print(f"\nğŸš€ ç”¨æˆ·è¾“å…¥: {query}")
    
    # --- Step 1: è·¯ç”± (æ‰¾æŠ½è±¡æ–¹å‘) ---
    classifier = IntentClassifier(model)
    category = classifier.classify(query)
    print(f"ğŸ“¡ Step 1 æ„å›¾åˆ†ç±»: [{category}]")
    
    selected_tools = []
    system_instruction = ""

    # æ ¹æ®åˆ†ç±»ç»“æœï¼ŒåŠ¨æ€åŠ è½½å·¥å…·åŒ…
    if category == "MATH":
        selected_tools = math_tools
        system_instruction = "ä½ æ˜¯ä¸€ä¸ªæ•°å­¦åŠ©æ‰‹ã€‚è¯·ä½¿ç”¨å·¥å…·è¿›è¡Œè®¡ç®—ã€‚"
    elif category == "INFO":
        selected_tools = info_tools
        system_instruction = "ä½ æ˜¯ä¸€ä¸ªä¿¡æ¯æŸ¥è¯¢åŠ©æ‰‹ã€‚è¯·ä½¿ç”¨å·¥å…·æŸ¥è¯¢ä¿¡æ¯ã€‚"
    else:
        print("ğŸ¤– ç›´æ¥å›å¤ï¼ˆæ— å·¥å…·ï¼‰: å¥½çš„ï¼Œæˆ‘ä»¬å¯ä»¥èŠèŠåˆ«çš„ã€‚")
        # è¿™é‡Œå¯ä»¥ç›´æ¥è°ƒç”¨æ— å·¥å…·çš„ LLM è¿›è¡Œé—²èŠ
        response = model.invoke([HumanMessage(content=query)])
        print(f"ğŸ’¬ å›å¤: {response.content}")
        return

    # --- Step 2: ç»‘å®šå…·ä½“å·¥å…·å¹¶æ‰§è¡Œ (æ‰¾å…·ä½“å·¥å…·) ---
    print(f"ğŸ› ï¸  Step 2 åŠ è½½å·¥å…·åŒ…: {[t.name for t in selected_tools]}")
    
    # åŠ¨æ€ç»‘å®šå·¥å…·ï¼
    # å…³é”®ç‚¹ï¼šè¿™é‡Œçš„ model æ­¤æ—¶åªâ€œçœ‹å¾—åˆ°â€ä¸å½“å‰æ„å›¾ç›¸å…³çš„å‡ ä¸ªå·¥å…·ï¼Œè€Œä¸æ˜¯å…¨éƒ¨ã€‚
    agent_executor = model.bind_tools(selected_tools)
    
    messages = [
        SystemMessage(content=system_instruction),
        HumanMessage(content=query)
    ]
    
    ai_msg = agent_executor.invoke(messages)
    
    # å¤„ç†å·¥å…·è°ƒç”¨ç»“æœ (ç®€åŒ–ç‰ˆé€»è¾‘)
    if ai_msg.tool_calls:
        for tool_call in ai_msg.tool_calls:
            print(f"ğŸ¯ Step 3 å†³å®šè°ƒç”¨å…·ä½“å·¥å…·: {tool_call['name']} å‚æ•°: {tool_call['args']}")
            # è¿™é‡Œä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬å°±ä¸çœŸçš„æ‰§è¡Œåç»­å›ç¯äº†ï¼Œåªå±•ç¤ºå†³ç­–è¿‡ç¨‹
            # çœŸå®åœºæ™¯ä¼šæ‰§è¡Œå·¥å…· -> æ‹¿åˆ°ç»“æœ -> å†ä¸¢ç»™ LLM ç»„ç»‡è¯­è¨€
            
            # ç®€å•æ¨¡æ‹Ÿæ‰§è¡Œï¼Œä¸ºäº†è®©è¾“å‡ºå®Œæ•´
            tools_map = {t.name: t for t in selected_tools}
            tool_func = tools_map[tool_call['name']]
            res = tool_func.invoke(tool_call['args'])
            print(f"   â†³ æ‰§è¡Œç»“æœ: {res}")

    else:
        print(f"ğŸ¤– Step 3 AI å†³å®šä¸è°ƒç”¨å·¥å…·ï¼Œç›´æ¥å›å¤: {ai_msg.content}")

# ==========================================
# è¿è¡Œæ¼”ç¤º
# ==========================================
if __name__ == "__main__":
    print("=== åˆ†å±‚å·¥å…·é€‰æ‹©æ¨¡å¼ (Hierarchical Tool Selection) ===")
    
    # Case 1: æ•°å­¦é—®é¢˜
    run_hierarchical_agent("è®¡ç®— 123 ä¹˜ä»¥ 456 æ˜¯å¤šå°‘ï¼Ÿ")
    
    # Case 2: ä¿¡æ¯æŸ¥è¯¢
    run_hierarchical_agent("åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
    
    # Case 3: æ··åˆ/é—²èŠ
    run_hierarchical_agent("ä½ å¥½ï¼Œè®²ä¸ªç¬‘è¯å§")
