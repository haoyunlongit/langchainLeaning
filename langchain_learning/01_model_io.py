import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# 0. åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ==========================================
# Model Factory (ç±»ä¼¼ ViewModelFactory)
# ==========================================
def get_model(provider="openai"):
    """
    æ ¹æ® provider è¿”å›ä¸åŒçš„ Model å®ç°ã€‚
    è¿™å°±åƒ Android ä¸­çš„ Product Flavors æˆ–è€… Dependency Injection (Hilt/Dagger)ã€‚
    """
    if provider == "openai":
        print(f"ğŸ”„ æ­£åœ¨åˆå§‹åŒ– OpenAI Model...")
        return ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.7
        )
    
    elif provider == "deepseek":
        print(f"ğŸ”„ æ­£åœ¨åˆå§‹åŒ– DeepSeek Model (via OpenAI Protocol)...")
        # DeepSeek å…¼å®¹ OpenAI åè®®ï¼Œåªéœ€è¦ä¿®æ”¹ base_url å’Œ api_key
        return ChatOpenAI(
            model="deepseek-chat",
            openai_api_key=os.getenv("DEEPSEEK_API_KEY"),
            openai_api_base=os.getenv("DEEPSEEK_API_BASE"),
            temperature=0.7
        )
        
    elif provider == "google":
        print(f"ğŸ”„ æ­£åœ¨åˆå§‹åŒ– Google Gemini Model...")
        # éœ€è¦ pip install langchain-google-genai
        if not os.getenv("GOOGLE_API_KEY"):
            raise ValueError("è¯·åœ¨ .env ä¸­é…ç½® GOOGLE_API_KEY")
        return ChatGoogleGenerativeAI(
            model="gemini-pro",
            temperature=0.7
        )
    
    else:
        raise ValueError(f"Unknown provider: {provider}")

# ==========================================
# é˜¶æ®µä¸€ï¼šModel I/O (View & ViewModel)
# ==========================================

# 1. é€‰æ‹©ä½ çš„ "Flavor" (è¿™é‡Œä½ å¯ä»¥ä¿®æ”¹ä¸º 'deepseek' æˆ– 'google' æ¥æµ‹è¯•)
#CURRENT_PROVIDER = "openai" 
CURRENT_PROVIDER = "deepseek"
# CURRENT_PROVIDER = "google"

try:
    # åˆå§‹åŒ– Model
    model = get_model(CURRENT_PROVIDER)

    # 2. å®šä¹‰ Prompt (Intent)
    prompt_template = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·ç›´æ¥è¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦å¸¦æœ‰å¤šä½™çš„è§£é‡Šã€‚"),
        ("user", "è¯·å°†è¿™æ®µæ–‡å­—ç¿»è¯‘æˆ {language}: {text}")
    ])

    # 3. å®šä¹‰ Parser
    parser = StrOutputParser()

    # 4. æ„å»º Chain (LCEL Stream)
    chain = prompt_template | model | parser

    # 5. æ‰§è¡Œ
    print(f"--- å¼€å§‹ç¿»è¯‘ä»»åŠ¡ [{CURRENT_PROVIDER}] ---")
    input_data = {"language": "è‹±æ–‡", "text": "LangChain è®©åˆ‡æ¢å¤§æ¨¡å‹å˜å¾—åƒåˆ‡æ¢ Android ä¸»é¢˜ä¸€æ ·ç®€å•ã€‚"}
    
    result = chain.invoke(input_data)
    
    print(f"åŸæ–‡: {input_data['text']}")
    print(f"è¯‘æ–‡: {result}")

except Exception as e:
    print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
    print("æç¤º: è¯·æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦é…ç½®äº†å¯¹åº”çš„ API Key")
